#!/usr/bin/env python3
"""
è°ƒè¯•æµ‹è¯•è„šæœ¬ - åˆ†æQANNæ€§èƒ½é—®é¢˜
"""

import torch
import torch.nn as nn
import copy
from torchvision import datasets, transforms
from tqdm import tqdm
import time

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from spike_quan_wrapper_ICML import myquan_replace_resnet
import resnet


def build_test_dataset():
    """æ„å»ºæµ‹è¯•æ•°æ®é›†"""
    mean = [0.4914, 0.4822, 0.4465]
    std = [0.2023, 0.1994, 0.2010]
    
    test_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean, std)
    ])
    
    testset = datasets.CIFAR10(root='/home/zilingwei/cifar10', train=False, download=True, transform=test_transform)
    return testset


def create_test_dataloader(dataset, batch_size=128):
    """åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨"""
    test_loader = torch.utils.data.DataLoader(
        dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=4, 
        pin_memory=torch.cuda.is_available()
    )
    return test_loader


def test_model_detailed(model, test_loader, model_name="Model"):
    """è¯¦ç»†æµ‹è¯•æ¨¡å‹æ€§èƒ½"""
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    model.eval()
    
    correct = 0
    total = 0
    total_time = 0
    
    print(f"\nğŸ§ª è¯¦ç»†æµ‹è¯•{model_name}æ¨¡å‹...")
    
    with torch.no_grad():
        test_pbar = tqdm(test_loader, desc=f"æµ‹è¯•{model_name}", unit="batch")
        
        for batch_idx, (data, target) in enumerate(test_pbar):
            data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)
            
            # è®¡ç®—æ¨ç†æ—¶é—´
            torch.cuda.synchronize()  # ç¡®ä¿åŒæ­¥
            start_time = time.time()
            output = model(data)
            torch.cuda.synchronize()  # ç¡®ä¿åŒæ­¥
            inference_time = time.time() - start_time
            total_time += inference_time
            
            _, predicted = output.max(1)
            total += target.size(0)
            correct += predicted.eq(target).sum().item()
            
            # æ›´æ–°è¿›åº¦æ¡
            current_acc = 100. * correct / total
            test_pbar.set_postfix({
                'Acc': f'{current_acc:.2f}%',
                'Time': f'{inference_time*1000:.1f}ms'
            })
            
            # åªæµ‹è¯•å‰å‡ ä¸ªbatchæ¥å¿«é€Ÿè°ƒè¯•
            if batch_idx >= 10:  # åªæµ‹è¯•å‰10ä¸ªbatch
                break
    
    accuracy = 100. * correct / total
    avg_time_per_batch = total_time / min(11, len(test_loader))
    avg_time_per_sample = total_time / total
    
    print(f"âœ… {model_name}æµ‹è¯•å®Œæˆ (å‰{min(11, len(test_loader))}ä¸ªbatch):")
    print(f"   ğŸ“Š å‡†ç¡®ç‡: {accuracy:.2f}%")
    print(f"   â±ï¸  å¹³å‡æ¯batchæ—¶é—´: {avg_time_per_batch*1000:.2f}ms")
    print(f"   ğŸš€ å¹³å‡æ¯æ ·æœ¬æ—¶é—´: {avg_time_per_sample*1000:.3f}ms")
    
    return accuracy, avg_time_per_sample


def load_model_weights(model, model_path, model_name):
    """åŠ è½½æ¨¡å‹æƒé‡"""
    try:
        print(f"ğŸ“‚ åŠ è½½{model_name}æ¨¡å‹: {model_path}")
        checkpoint = torch.load(model_path, map_location='cpu')
        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint)
        print(f"âœ… {model_name}æ¨¡å‹åŠ è½½æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ åŠ è½½{model_name}æ¨¡å‹å¤±è´¥: {e}")
        return False


def debug_quantization_levels():
    """è°ƒè¯•ä¸åŒé‡åŒ–çº§åˆ«çš„å½±å“"""
    print("\n" + "="*60)
    print("ğŸ”¬ è°ƒè¯•é‡åŒ–çº§åˆ«å¯¹æ€§èƒ½çš„å½±å“")
    print("="*60)
    
    # å‡†å¤‡æ•°æ®
    test_set = build_test_dataset()
    test_loader = create_test_dataloader(test_set, 128)
    
    # åŠ è½½åŸºç¡€ANNæ¨¡å‹
    ann_model = resnet.resnet18(pretrained=False)
    ann_model.fc = torch.nn.Linear(ann_model.fc.in_features, 10)
    
    if not load_model_weights(ann_model, "best_ANN.pth", "ANN"):
        print("âŒ æ— æ³•åŠ è½½åŸºç¡€ANNæ¨¡å‹")
        return
    
    # æµ‹è¯•åŸå§‹ANN
    print("\nğŸ“Š æµ‹è¯•åŸºç¡€ANNæ¨¡å‹")
    ann_acc, ann_time = test_model_detailed(ann_model, test_loader, "ANN")
    
    # æµ‹è¯•ä¸åŒçš„é‡åŒ–çº§åˆ«
    levels = [4, 8, 16, 32]
    
    for level in levels:
        print(f"\nğŸ“Š æµ‹è¯•Level {level}é‡åŒ–")
        
        # æ·±åº¦å¤åˆ¶æ¨¡å‹
        qann_model = copy.deepcopy(ann_model)
        
        # åº”ç”¨é‡åŒ–
        print(f"ğŸ”„ åº”ç”¨Level {level}é‡åŒ–...")
        myquan_replace_resnet(qann_model, level=level, weight_bit=32, is_softmax=False)
        
        # æµ‹è¯•é‡åŒ–æ¨¡å‹
        qann_acc, qann_time = test_model_detailed(qann_model, test_loader, f"QANN-L{level}")
        
        # è®¡ç®—æ€§èƒ½å˜åŒ–
        acc_drop = ann_acc - qann_acc
        speed_ratio = ann_time / qann_time
        
        print(f"   ğŸ“ˆ å‡†ç¡®ç‡å˜åŒ–: {ann_acc:.2f}% â†’ {qann_acc:.2f}% ({acc_drop:+.2f}%)")
        print(f"   ğŸš€ é€Ÿåº¦å˜åŒ–: {speed_ratio:.2f}x")
        
        # æ¸…ç†å†…å­˜
        del qann_model
        torch.cuda.empty_cache()


def debug_model_structure():
    """è°ƒè¯•æ¨¡å‹ç»“æ„å˜åŒ–"""
    print("\n" + "="*60)
    print("ğŸ”¬ è°ƒè¯•æ¨¡å‹ç»“æ„å˜åŒ–")
    print("="*60)
    
    # åˆ›å»ºåŸºç¡€æ¨¡å‹
    ann_model = resnet.resnet18(pretrained=False)
    ann_model.fc = torch.nn.Linear(ann_model.fc.in_features, 10)
    
    print("ğŸ“‹ åŸå§‹ANNæ¨¡å‹ç»“æ„:")
    print("reluå±‚æ•°é‡:", sum(1 for m in ann_model.modules() if isinstance(m, nn.ReLU)))
    
    # åº”ç”¨é‡åŒ–
    qann_model = copy.deepcopy(ann_model)
    myquan_replace_resnet(qann_model, level=8, weight_bit=32, is_softmax=False)
    
    print("\nğŸ“‹ é‡åŒ–åQANNæ¨¡å‹ç»“æ„:")
    from spike_quan_layer import MyQuan
    print("MyQuanå±‚æ•°é‡:", sum(1 for m in qann_model.modules() if isinstance(m, MyQuan)))
    print("ReLUå±‚æ•°é‡:", sum(1 for m in qann_model.modules() if isinstance(m, nn.ReLU)))
    
    # æ£€æŸ¥é‡åŒ–å±‚çš„å‚æ•°
    print("\nğŸ” é‡åŒ–å±‚å‚æ•°:")
    for name, module in qann_model.named_modules():
        if isinstance(module, MyQuan):
            print(f"  {name}: level={module.pos_max}, threshold={module.s.item():.4f}")


def main():
    print("ğŸ”¬ QANNæ€§èƒ½è°ƒè¯•è„šæœ¬")
    print(f"ğŸ“± è®¾å¤‡: {'CUDA' if torch.cuda.is_available() else 'CPU'}")
    
    # è°ƒè¯•1: æ¨¡å‹ç»“æ„å˜åŒ–
    debug_model_structure()
    
    # è°ƒè¯•2: ä¸åŒé‡åŒ–çº§åˆ«çš„å½±å“  
    debug_quantization_levels()
    
    print("\nğŸ‰ è°ƒè¯•å®Œæˆï¼")


if __name__ == "__main__":
    main()