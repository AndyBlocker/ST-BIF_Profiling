#!/usr/bin/env python3
"""
æ¨¡å‹æµ‹è¯•è„šæœ¬ - åªæµ‹è¯•ä¸è®­ç»ƒ
æ”¯æŒæµ‹è¯•ANNã€QANNã€SNNä¸‰ç§æ¨¡å‹çš„æ€§èƒ½
"""

import torch
import torch.nn as nn
import os
import argparse
from torchvision import datasets, transforms
from tqdm import tqdm
import time

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from spike_quan_wrapper_ICML import SNNWrapper_MS, myquan_replace_resnet
import resnet


def build_test_dataset():
    """æ„å»ºæµ‹è¯•æ•°æ®é›†"""
    # CIFAR10çš„æ ‡å‡†å‡å€¼å’Œæ ‡å‡†å·®
    mean = [0.4914, 0.4822, 0.4465]
    std = [0.2023, 0.1994, 0.2010]
    
    # æµ‹è¯•æ•°æ®é¢„å¤„ç†ï¼ˆä¸ä½¿ç”¨å¢å¼ºï¼‰
    test_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean, std)
    ])
    
    testset = datasets.CIFAR10(root='/home/zilingwei/cifar10', train=False, download=True, transform=test_transform)
    return testset


def create_test_dataloader(dataset, batch_size=128):
    """åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨"""
    test_loader = torch.utils.data.DataLoader(
        dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=4, 
        pin_memory=torch.cuda.is_available()
    )
    return test_loader


def test_model(model, test_loader, model_name="Model"):
    """æµ‹è¯•æ¨¡å‹æ€§èƒ½"""
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    model.eval()
    
    correct = 0
    total = 0
    total_time = 0
    
    print(f"\nğŸ§ª æµ‹è¯•{model_name}æ¨¡å‹...")
    
    with torch.no_grad():
        test_pbar = tqdm(test_loader, desc=f"æµ‹è¯•{model_name}", unit="batch")
        
        for data, target in test_pbar:
            data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)
            
            # è®¡ç®—æ¨ç†æ—¶é—´
            start_time = time.time()
            output = model(data)
            inference_time = time.time() - start_time
            total_time += inference_time
            
            _, predicted = output.max(1)
            total += target.size(0)
            correct += predicted.eq(target).sum().item()
            
            # æ›´æ–°è¿›åº¦æ¡
            current_acc = 100. * correct / total
            test_pbar.set_postfix({
                'Acc': f'{current_acc:.2f}%',
                'Time': f'{inference_time*1000:.1f}ms'
            })
    
    accuracy = 100. * correct / total
    avg_time_per_batch = total_time / len(test_loader)
    avg_time_per_sample = total_time / total
    
    print(f"âœ… {model_name}æµ‹è¯•å®Œæˆ:")
    print(f"   ğŸ“Š å‡†ç¡®ç‡: {accuracy:.2f}%")
    print(f"   â±ï¸  å¹³å‡æ¯batchæ—¶é—´: {avg_time_per_batch*1000:.2f}ms")
    print(f"   ğŸš€ å¹³å‡æ¯æ ·æœ¬æ—¶é—´: {avg_time_per_sample*1000:.3f}ms")
    print(f"   ğŸ¯ ååé‡: {1/avg_time_per_sample:.1f} samples/sec")
    
    return accuracy, avg_time_per_sample


def load_model_weights(model, model_path, model_name):
    """åŠ è½½æ¨¡å‹æƒé‡"""
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return False
    
    try:
        print(f"ğŸ“‚ åŠ è½½{model_name}æ¨¡å‹: {model_path}")
        
        # å°è¯•åŠ è½½checkpointæ ¼å¼
        checkpoint = torch.load(model_path, map_location='cpu')
        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
            if 'best_acc' in checkpoint:
                print(f"   ğŸ† è®­ç»ƒæ—¶æœ€ä½³å‡†ç¡®ç‡: {checkpoint['best_acc']:.2f}%")
        else:
            # ç›´æ¥åŠ è½½state_dict
            model.load_state_dict(checkpoint)
        
        print(f"âœ… {model_name}æ¨¡å‹åŠ è½½æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ åŠ è½½{model_name}æ¨¡å‹å¤±è´¥: {e}")
        return False


def test_ann_model(test_loader, model_path="best_ANN.pth"):
    """æµ‹è¯•ANNæ¨¡å‹"""
    print("\n" + "="*50)
    print("ğŸ§  æµ‹è¯•ANNæ¨¡å‹")
    print("="*50)
    
    # åˆ›å»ºANNæ¨¡å‹
    model = resnet.resnet18(pretrained=False)
    model.fc = torch.nn.Linear(model.fc.in_features, 10)
    
    # åŠ è½½æƒé‡
    if not load_model_weights(model, model_path, "ANN"):
        return None
    
    # æµ‹è¯•æ¨¡å‹
    accuracy, inference_time = test_model(model, test_loader, "ANN")
    return {"accuracy": accuracy, "inference_time": inference_time}


def test_qann_model(test_loader, model_path="best_QANN.pth"):
    """æµ‹è¯•QANNæ¨¡å‹"""
    print("\n" + "="*50)
    print("âš¡ æµ‹è¯•QANNæ¨¡å‹")
    print("="*50)
    
    # åˆ›å»ºANNæ¨¡å‹
    model = resnet.resnet18(pretrained=False)
    model.fc = torch.nn.Linear(model.fc.in_features, 10)
    
    # è½¬æ¢ä¸ºQANN
    print("ğŸ”„ è½¬æ¢ä¸ºQANN...")
    myquan_replace_resnet(model, level=8, weight_bit=32, is_softmax=False)
    print("âœ… æ¨¡å‹å·²è½¬æ¢ä¸ºQANN")
    
    # åŠ è½½æƒé‡
    if not load_model_weights(model, model_path, "QANN"):
        return None
    
    # æµ‹è¯•æ¨¡å‹
    accuracy, inference_time = test_model(model, test_loader, "QANN")
    return {"accuracy": accuracy, "inference_time": inference_time}


def test_snn_model(test_loader, model_path="best_SNN.pth"):
    """æµ‹è¯•SNNæ¨¡å‹"""
    print("\n" + "="*50)
    print("ğŸ§  æµ‹è¯•SNNæ¨¡å‹")
    print("="*50)
    
    # åˆ›å»ºANNæ¨¡å‹
    ann_model = resnet.resnet18(pretrained=False)
    ann_model.fc = torch.nn.Linear(ann_model.fc.in_features, 10)
    
    # è½¬æ¢ä¸ºQANN
    print("ğŸ”„ è½¬æ¢ä¸ºQANN...")
    myquan_replace_resnet(ann_model, level=8, weight_bit=32, is_softmax=False)
    
    # è½¬æ¢ä¸ºSNN
    print("ğŸ”„ è½¬æ¢ä¸ºSNN...")
    output_dir = "/home/zilingwei/output_bin_snn_resnet_w32_a4_T8/"
    os.makedirs(output_dir, exist_ok=True)
    
    snn_model = SNNWrapper_MS(
        ann_model=ann_model, 
        cfg=None, 
        time_step=8,
        Encoding_type="analog", 
        level=8, 
        neuron_type="ST-BIF",
        model_name="resnet", 
        is_softmax=False,  
        suppress_over_fire=False,
        record_inout=False,
        learnable=True,
        record_dir=output_dir
    )
    print("âœ… æ¨¡å‹å·²è½¬æ¢ä¸ºSNN")
    
    # åŠ è½½æƒé‡
    if not load_model_weights(snn_model, model_path, "SNN"):
        return None
    
    # æµ‹è¯•æ¨¡å‹
    accuracy, inference_time = test_model(snn_model, test_loader, "SNN")
    return {"accuracy": accuracy, "inference_time": inference_time}


def compare_models(results):
    """æ¯”è¾ƒæ¨¡å‹æ€§èƒ½"""
    print("\n" + "="*60)
    print("ğŸ“Š æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
    print("="*60)
    
    print(f"{'æ¨¡å‹ç±»å‹':<10} {'å‡†ç¡®ç‡':<10} {'æ¨ç†æ—¶é—´':<15} {'ç›¸å¯¹é€Ÿåº¦':<10}")
    print("-" * 60)
    
    if 'ANN' in results and results['ANN'] is not None:
        ann_time = results['ANN']['inference_time']
        baseline_time = ann_time
    else:
        baseline_time = None
    
    for model_type, result in results.items():
        if result is not None:
            acc = result['accuracy']
            time_ms = result['inference_time'] * 1000
            
            if baseline_time:
                speed_ratio = baseline_time / result['inference_time']
                speed_str = f"{speed_ratio:.2f}x"
            else:
                speed_str = "N/A"
            
            print(f"{model_type:<10} {acc:<9.2f}% {time_ms:<13.3f}ms {speed_str:<10}")
    
    print("-" * 60)


def main():
    parser = argparse.ArgumentParser(description='æµ‹è¯•ANN/QANN/SNNæ¨¡å‹æ€§èƒ½')
    parser.add_argument('--models', nargs='+', choices=['ann', 'qann', 'snn', 'all'], 
                       default=['all'], help='è¦æµ‹è¯•çš„æ¨¡å‹ç±»å‹')
    parser.add_argument('--batch-size', type=int, default=128, help='æµ‹è¯•batch size')
    parser.add_argument('--ann-path', default='best_ANN.pth', help='ANNæ¨¡å‹è·¯å¾„')
    parser.add_argument('--qann-path', default='best_QANN.pth', help='QANNæ¨¡å‹è·¯å¾„') 
    parser.add_argument('--snn-path', default='best_SNN.pth', help='SNNæ¨¡å‹è·¯å¾„')
    
    args = parser.parse_args()
    
    print("ğŸ¯ æ¨¡å‹æµ‹è¯•è„šæœ¬")
    print(f"ğŸ“± è®¾å¤‡: {'CUDA' if torch.cuda.is_available() else 'CPU'}")
    print(f"ğŸ“¦ Batch Size: {args.batch_size}")
    
    # å‡†å¤‡æ•°æ®
    print("\nğŸ“Š å‡†å¤‡æµ‹è¯•æ•°æ®...")
    test_set = build_test_dataset()
    test_loader = create_test_dataloader(test_set, args.batch_size)
    print(f"âœ… æµ‹è¯•é›†å¤§å°: {len(test_set)} æ ·æœ¬")
    
    # æµ‹è¯•æ¨¡å‹
    results = {}
    
    if 'all' in args.models or 'ann' in args.models:
        results['ANN'] = test_ann_model(test_loader, args.ann_path)
    
    if 'all' in args.models or 'qann' in args.models:
        results['QANN'] = test_qann_model(test_loader, args.qann_path)
    
    if 'all' in args.models or 'snn' in args.models:
        results['SNN'] = test_snn_model(test_loader, args.snn_path)
    
    # æ¯”è¾ƒç»“æœ
    if len(results) > 1:
        compare_models(results)
    
    print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    main()